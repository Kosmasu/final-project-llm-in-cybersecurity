{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6205c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded /home/kosmas/projects/llm-in-cybersecurity/final-project/datasets/raw/CEAS_08.csv: 39154 rows\n",
      "Loaded /home/kosmas/projects/llm-in-cybersecurity/final-project/datasets/raw/Enron.csv: 29767 rows\n",
      "Loaded /home/kosmas/projects/llm-in-cybersecurity/final-project/datasets/raw/Ling.csv: 2859 rows\n",
      "Loaded /home/kosmas/projects/llm-in-cybersecurity/final-project/datasets/raw/SpamAssasin.csv: 5809 rows\n",
      "Error loading /home/kosmas/projects/llm-in-cybersecurity/final-project/datasets/raw/TREC_05.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error loading /home/kosmas/projects/llm-in-cybersecurity/final-project/datasets/raw/TREC_06.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Loaded /home/kosmas/projects/llm-in-cybersecurity/final-project/datasets/raw/TREC_07.csv: 53757 rows\n",
      "\n",
      "Analyzing dataset structures...\n",
      "Dataset 0 (CEAS_08.csv): Columns = ['sender', 'receiver', 'date', 'subject', 'body', 'label', 'urls', 'source']\n",
      "Dataset 1 (Enron.csv): Columns = ['subject', 'body', 'label', 'source']\n",
      "Dataset 2 (Ling.csv): Columns = ['subject', 'body', 'label', 'source']\n",
      "Dataset 3 (SpamAssasin.csv): Columns = ['sender', 'receiver', 'date', 'subject', 'body', 'label', 'urls', 'source']\n",
      "Dataset 4 (TREC_05.csv): Columns = ['sender', 'receiver', 'date', 'subject', 'body', 'label', 'urls', 'source']\n",
      "\n",
      "Merging datasets...\n",
      "Merged dataset shape: (131346, 8)\n",
      "Merged dataset saved to /home/kosmas/projects/llm-in-cybersecurity/final-project/datasets/raw/../merged_emails.csv\n",
      "\n",
      "Split sizes:\n",
      "Training set: 91942 rows (70.0%)\n",
      "Validation set: 19702 rows (15.0%)\n",
      "Test set: 19702 rows (15.0%)\n",
      "Dataset splits saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the dataset folder path\n",
    "base_path = '/home/kosmas/projects/llm-in-cybersecurity/final-project/datasets/raw/'\n",
    "\n",
    "# List of datasets to merge\n",
    "dataset_files = [\n",
    "    'CEAS_08.csv',\n",
    "    'Enron.csv',\n",
    "    'Ling.csv',\n",
    "    'SpamAssasin.csv',\n",
    "    'TREC_05.csv',\n",
    "    'TREC_06.csv',\n",
    "    'TREC_07.csv'\n",
    "]\n",
    "\n",
    "# Function to read and preprocess each dataset\n",
    "def load_dataset(file_path):\n",
    "    try:\n",
    "        # Try to determine the file's format and load accordingly\n",
    "        df = pd.read_csv(file_path, encoding='utf-8')\n",
    "        \n",
    "        # Check if the dataset has the expected structure\n",
    "        # Most email datasets should have at least 2 columns (text and label)\n",
    "        if df.shape[1] < 2:\n",
    "            print(f\"Warning: {file_path} has fewer than 2 columns. Skipping.\")\n",
    "            return None\n",
    "        \n",
    "        # Add a source column to track which dataset each row came from\n",
    "        df['source'] = os.path.basename(file_path)\n",
    "        \n",
    "        # Some basic preprocessing\n",
    "        print(f\"Loaded {file_path}: {df.shape[0]} rows\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load and merge all datasets\n",
    "dfs = []\n",
    "for file in dataset_files:\n",
    "    file_path = os.path.join(base_path, file)\n",
    "    if os.path.exists(file_path):\n",
    "        df = load_dataset(file_path)\n",
    "        if df is not None:\n",
    "            dfs.append(df)\n",
    "    else:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "\n",
    "# Check if we have any dataframes to merge\n",
    "if not dfs:\n",
    "    print(\"No valid datasets found!\")\n",
    "else:\n",
    "    # Determine common columns for standardization\n",
    "    print(\"\\nAnalyzing dataset structures...\")\n",
    "    for i, df in enumerate(dfs):\n",
    "        print(f\"Dataset {i} ({dataset_files[i]}): Columns = {df.columns.tolist()}\")\n",
    "    \n",
    "    # Merge all datasets (this may need customization based on column structure)\n",
    "    print(\"\\nMerging datasets...\")\n",
    "    # We'll customize this part after examining the actual structure of your datasets\n",
    "    # For now, we'll assume a simple concat operation\n",
    "    merged_df = pd.concat(dfs, ignore_index=True, sort=False)\n",
    "    \n",
    "    print(f\"Merged dataset shape: {merged_df.shape}\")\n",
    "    \n",
    "    # Save the merged dataset\n",
    "    merged_path = os.path.join(base_path, '../merged_emails.csv')\n",
    "    merged_df.to_csv(merged_path, index=False)\n",
    "    print(f\"Merged dataset saved to {merged_path}\")\n",
    "    \n",
    "    # Split into train, validation, and test sets (70%, 15%, 15%)\n",
    "    # First split: 70% train, 30% temp\n",
    "    train_df, temp_df = train_test_split(merged_df, test_size=0.3, random_state=42, stratify=merged_df['label'] if 'label' in merged_df.columns else None)\n",
    "    \n",
    "    # Second split: divide the temp into validation and test (50% each of the 30%, so 15% of original dataset)\n",
    "    val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df['label'] if 'label' in temp_df.columns else None)\n",
    "    \n",
    "    print(f\"\\nSplit sizes:\")\n",
    "    print(f\"Training set: {train_df.shape[0]} rows ({train_df.shape[0]/merged_df.shape[0]:.1%})\")\n",
    "    print(f\"Validation set: {val_df.shape[0]} rows ({val_df.shape[0]/merged_df.shape[0]:.1%})\")\n",
    "    print(f\"Test set: {test_df.shape[0]} rows ({test_df.shape[0]/merged_df.shape[0]:.1%})\")\n",
    "    \n",
    "    # Save the split datasets\n",
    "    train_df.to_csv(os.path.join(base_path, '../train_emails.csv'), index=False)\n",
    "    val_df.to_csv(os.path.join(base_path, '../val_emails.csv'), index=False)\n",
    "    test_df.to_csv(os.path.join(base_path, '../test_emails.csv'), index=False)\n",
    "    print(\"Dataset splits saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dee0960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing 5 random samples from each of the 5 sources\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sender</th>\n",
       "      <th>receiver</th>\n",
       "      <th>date</th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "      <th>urls</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jeff Chan &lt;ociwu@surbl.org&gt;</td>\n",
       "      <td>zqoqi@spamassassin.apache.org</td>\n",
       "      <td>Tue, 05 Aug 2008 18:31:40 -0600</td>\n",
       "      <td>Re: what are the criteria for being listed in\\...</td>\n",
       "      <td>Also, the sa-blacklist inclusion policy is at:...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CEAS_08.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Freeman Cabrera &lt;ChadwickzerothRosario@million...</td>\n",
       "      <td>twanna_patient@gvc.ceas-challenge.cc</td>\n",
       "      <td>Wed, 06 Aug 2008 04:32:27 -0200</td>\n",
       "      <td>Guaranteed Erection Fast</td>\n",
       "      <td>\\nSize DOES matter - change your life today!\\n...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CEAS_08.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Daily Top 10 &lt;notelliu1989@arte-m.de&gt;</td>\n",
       "      <td>user8.2-ext1@gvc.ceas-challenge.cc</td>\n",
       "      <td>Wed, 06 Aug 2008 15:31:48 +0200</td>\n",
       "      <td>CNN.com Daily Top 10</td>\n",
       "      <td>&gt;+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CEAS_08.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chris Poteet &lt;jhsluxg@siolon.com&gt;</td>\n",
       "      <td>PownceAPI &lt;zgdjhgesv@googlegroups.com&gt;</td>\n",
       "      <td>Wed, 06 Aug 2008 08:39:40 -0700</td>\n",
       "      <td>[PownceAPI] Dates in API?</td>\n",
       "      <td>\\nLet's say I wanted to return the actual date...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CEAS_08.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gene Oneil &lt;auralx8@pinnacleframe.com&gt;</td>\n",
       "      <td>user8.1@gvc.ceas-challenge.cc</td>\n",
       "      <td>Fri, 08 Aug 2008 11:15:14 +0200</td>\n",
       "      <td>Re:</td>\n",
       "      <td>\\nLove is the beginning of all the joy which n...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CEAS_08.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>karthik rajan - interview schedule</td>\n",
       "      <td>attached you will find the interview packet fo...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Enron.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>re : a 3 al ad hoc review team</td>\n",
       "      <td>in the week of the 25 th . , the 26 th and 27 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Enron.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not for sale in the u . a . e - usb voip hands...</td>\n",
       "      <td>not for sale in the u . a . e\\nusb voip handse...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Enron.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pharma</td>\n",
       "      <td>stop wasting money on prescription drugs . get...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Enron.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>california update - - 10 . 02 . 01 : puc turns...</td>\n",
       "      <td>agreement with dwr\\nin what will likely be vie...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Enron.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cfp nlp + ia ' 98 / taln ' 98 moncton , canada</td>\n",
       "      <td>* * * * * * * * * * * * * * * * * * * * * * ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ling.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dick armey 's slip and correction</td>\n",
       "      <td>i was curious if anyone was actually intereste...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ling.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>last cfp : acm sac ' 99 - track on coordination</td>\n",
       "      <td>* * * final call for papers and referees * * *...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ling.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>politeness theory</td>\n",
       "      <td>call for papers politeness theory and language...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ling.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>est-ce que questions</td>\n",
       "      <td>several weeks ago , i ' ve sent an inquiry abo...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ling.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Gary Lawrence Murphy &lt;garym@canada.com&gt;</td>\n",
       "      <td>James Rogers &lt;jamesr@best.com&gt;</td>\n",
       "      <td>08 Sep 2002 23:12:53 -0400</td>\n",
       "      <td>Re: whoa</td>\n",
       "      <td>&gt;&gt;&gt;&gt;&gt; \"J\" == James Rogers  writes:     J&gt; ... ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SpamAssasin.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\"Joseph S. Barrera III\" &lt;joe@barrera.org&gt;</td>\n",
       "      <td>Lucas Gonze &lt;lgonze@panix.com&gt;</td>\n",
       "      <td>Tue, 23 Jul 2002 08:58:55 -0700</td>\n",
       "      <td>Re: spam maps</td>\n",
       "      <td>Lucas Gonze wrote:\\n&gt;&gt;- Joe\\n&gt;&gt;\\n&gt;&gt;P.S. I hate...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SpamAssasin.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Lockergnome Digital Media &lt;subscriptions@locke...</td>\n",
       "      <td>qqqqqqqqqq-lg@example.com</td>\n",
       "      <td>Wed, 17 Jul 2002 23:39:29 -0500</td>\n",
       "      <td>[Lockergnome Digital Media]  Endorsed Compatib...</td>\n",
       "      <td>![Lockergnome](http://images.lockergnome.com/i...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SpamAssasin.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\"garry\" &lt;ggs020255@hotmail.com&gt;</td>\n",
       "      <td>fork@spamassassin.taint.org</td>\n",
       "      <td>Wed, 24 Jul 2002 19:14:09 -0700</td>\n",
       "      <td>Greetings from Calif!</td>\n",
       "      <td>!Want to make a million bucks this year?\\nMe t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SpamAssasin.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>&lt;greenman@swbell.net&gt;</td>\n",
       "      <td>&lt;webmaster@efi.ie&gt;</td>\n",
       "      <td>Mon, 20 May 2002 05:24:29 +0500</td>\n",
       "      <td>Oh No! My Printer Died!</td>\n",
       "      <td>------=_NextPart_000_00C8_20D83C2D.E4417B07\\nC...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SpamAssasin.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mister_bluesman &lt;mister_bluesman@hotmail.com&gt;</td>\n",
       "      <td>r-help@stat.math.ethz.ch</td>\n",
       "      <td>Wed, 16 May 2007 08:36:36 -0700</td>\n",
       "      <td>Re: [R] Installing SJava - problem</td>\n",
       "      <td>\\nThank you for your help. Does that mean I am...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TREC_07.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>jpeach@samba.org</td>\n",
       "      <td>samba-cvs@samba.org</td>\n",
       "      <td>Tue, 15 May 2007 04:02:35 +0000</td>\n",
       "      <td>svn commit: samba-docs r1114 - in trunk/smbdot...</td>\n",
       "      <td>Author: jpeach\\nDate: 2007-05-15 04:02:34 +000...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TREC_07.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\"Richard M. Heiberger\" &lt;rmh@temple.edu&gt;</td>\n",
       "      <td>Chris Elsaesser &lt;chris.elsaesser@spadac.com&gt;, ...</td>\n",
       "      <td>Thu, 17 May 2007 11:37:06 -0400</td>\n",
       "      <td>Re: [R] using lm() with variable formula</td>\n",
       "      <td>&gt; tmp &lt;- data.frame(matrix(rnorm(40),10,4, dim...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TREC_07.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ramon WELLER &lt;krocwot@themagnumgroup.com&gt;</td>\n",
       "      <td>theorize@plg.uwaterloo.ca</td>\n",
       "      <td>Sun, 24 Jun 2007 07:46:58 +0300</td>\n",
       "      <td>Time to Win Time to Party Have Some FUN with O...</td>\n",
       "      <td>Paradise is here! Our casino paradise is lined...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TREC_07.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Tara Dill &lt;ovulebirches@rastamall.com&gt;</td>\n",
       "      <td>mail@flax9.uwaterloo.ca</td>\n",
       "      <td>Thu, 10 May 2007 19:04:39 -0100</td>\n",
       "      <td>Don't miss this unique chance</td>\n",
       "      <td>Dear customer.Wanna know how to save much on y...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TREC_07.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sender  \\\n",
       "0                         Jeff Chan <ociwu@surbl.org>   \n",
       "1   Freeman Cabrera <ChadwickzerothRosario@million...   \n",
       "2               Daily Top 10 <notelliu1989@arte-m.de>   \n",
       "3                   Chris Poteet <jhsluxg@siolon.com>   \n",
       "4              Gene Oneil <auralx8@pinnacleframe.com>   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14                                                NaN   \n",
       "15            Gary Lawrence Murphy <garym@canada.com>   \n",
       "16          \"Joseph S. Barrera III\" <joe@barrera.org>   \n",
       "17  Lockergnome Digital Media <subscriptions@locke...   \n",
       "18                    \"garry\" <ggs020255@hotmail.com>   \n",
       "19                              <greenman@swbell.net>   \n",
       "20      mister_bluesman <mister_bluesman@hotmail.com>   \n",
       "21                                   jpeach@samba.org   \n",
       "22            \"Richard M. Heiberger\" <rmh@temple.edu>   \n",
       "23          Ramon WELLER <krocwot@themagnumgroup.com>   \n",
       "24             Tara Dill <ovulebirches@rastamall.com>   \n",
       "\n",
       "                                             receiver  \\\n",
       "0                       zqoqi@spamassassin.apache.org   \n",
       "1                twanna_patient@gvc.ceas-challenge.cc   \n",
       "2                  user8.2-ext1@gvc.ceas-challenge.cc   \n",
       "3              PownceAPI <zgdjhgesv@googlegroups.com>   \n",
       "4                       user8.1@gvc.ceas-challenge.cc   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14                                                NaN   \n",
       "15                     James Rogers <jamesr@best.com>   \n",
       "16                     Lucas Gonze <lgonze@panix.com>   \n",
       "17                          qqqqqqqqqq-lg@example.com   \n",
       "18                        fork@spamassassin.taint.org   \n",
       "19                                 <webmaster@efi.ie>   \n",
       "20                           r-help@stat.math.ethz.ch   \n",
       "21                                samba-cvs@samba.org   \n",
       "22  Chris Elsaesser <chris.elsaesser@spadac.com>, ...   \n",
       "23                          theorize@plg.uwaterloo.ca   \n",
       "24                            mail@flax9.uwaterloo.ca   \n",
       "\n",
       "                               date  \\\n",
       "0   Tue, 05 Aug 2008 18:31:40 -0600   \n",
       "1   Wed, 06 Aug 2008 04:32:27 -0200   \n",
       "2   Wed, 06 Aug 2008 15:31:48 +0200   \n",
       "3   Wed, 06 Aug 2008 08:39:40 -0700   \n",
       "4   Fri, 08 Aug 2008 11:15:14 +0200   \n",
       "5                               NaN   \n",
       "6                               NaN   \n",
       "7                               NaN   \n",
       "8                               NaN   \n",
       "9                               NaN   \n",
       "10                              NaN   \n",
       "11                              NaN   \n",
       "12                              NaN   \n",
       "13                              NaN   \n",
       "14                              NaN   \n",
       "15       08 Sep 2002 23:12:53 -0400   \n",
       "16  Tue, 23 Jul 2002 08:58:55 -0700   \n",
       "17  Wed, 17 Jul 2002 23:39:29 -0500   \n",
       "18  Wed, 24 Jul 2002 19:14:09 -0700   \n",
       "19  Mon, 20 May 2002 05:24:29 +0500   \n",
       "20  Wed, 16 May 2007 08:36:36 -0700   \n",
       "21  Tue, 15 May 2007 04:02:35 +0000   \n",
       "22  Thu, 17 May 2007 11:37:06 -0400   \n",
       "23  Sun, 24 Jun 2007 07:46:58 +0300   \n",
       "24  Thu, 10 May 2007 19:04:39 -0100   \n",
       "\n",
       "                                              subject  \\\n",
       "0   Re: what are the criteria for being listed in\\...   \n",
       "1                            Guaranteed Erection Fast   \n",
       "2                                CNN.com Daily Top 10   \n",
       "3                           [PownceAPI] Dates in API?   \n",
       "4                                                 Re:   \n",
       "5                  karthik rajan - interview schedule   \n",
       "6                      re : a 3 al ad hoc review team   \n",
       "7   not for sale in the u . a . e - usb voip hands...   \n",
       "8                                              pharma   \n",
       "9   california update - - 10 . 02 . 01 : puc turns...   \n",
       "10     cfp nlp + ia ' 98 / taln ' 98 moncton , canada   \n",
       "11                  dick armey 's slip and correction   \n",
       "12    last cfp : acm sac ' 99 - track on coordination   \n",
       "13                                  politeness theory   \n",
       "14                               est-ce que questions   \n",
       "15                                           Re: whoa   \n",
       "16                                      Re: spam maps   \n",
       "17  [Lockergnome Digital Media]  Endorsed Compatib...   \n",
       "18                              Greetings from Calif!   \n",
       "19                            Oh No! My Printer Died!   \n",
       "20                 Re: [R] Installing SJava - problem   \n",
       "21  svn commit: samba-docs r1114 - in trunk/smbdot...   \n",
       "22           Re: [R] using lm() with variable formula   \n",
       "23  Time to Win Time to Party Have Some FUN with O...   \n",
       "24                      Don't miss this unique chance   \n",
       "\n",
       "                                                 body  label  urls  \\\n",
       "0   Also, the sa-blacklist inclusion policy is at:...      0   1.0   \n",
       "1   \\nSize DOES matter - change your life today!\\n...      1   1.0   \n",
       "2   >+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...      1   1.0   \n",
       "3   \\nLet's say I wanted to return the actual date...      0   1.0   \n",
       "4   \\nLove is the beginning of all the joy which n...      1   1.0   \n",
       "5   attached you will find the interview packet fo...      0   NaN   \n",
       "6   in the week of the 25 th . , the 26 th and 27 ...      0   NaN   \n",
       "7   not for sale in the u . a . e\\nusb voip handse...      1   NaN   \n",
       "8   stop wasting money on prescription drugs . get...      1   NaN   \n",
       "9   agreement with dwr\\nin what will likely be vie...      0   NaN   \n",
       "10  * * * * * * * * * * * * * * * * * * * * * * ca...      0   NaN   \n",
       "11  i was curious if anyone was actually intereste...      0   NaN   \n",
       "12  * * * final call for papers and referees * * *...      0   NaN   \n",
       "13  call for papers politeness theory and language...      0   NaN   \n",
       "14  several weeks ago , i ' ve sent an inquiry abo...      0   NaN   \n",
       "15  >>>>> \"J\" == James Rogers  writes:     J> ... ...      0   1.0   \n",
       "16  Lucas Gonze wrote:\\n>>- Joe\\n>>\\n>>P.S. I hate...      0   1.0   \n",
       "17  ![Lockergnome](http://images.lockergnome.com/i...      0   1.0   \n",
       "18  !Want to make a million bucks this year?\\nMe t...      1   1.0   \n",
       "19  ------=_NextPart_000_00C8_20D83C2D.E4417B07\\nC...      1   0.0   \n",
       "20  \\nThank you for your help. Does that mean I am...      0   1.0   \n",
       "21  Author: jpeach\\nDate: 2007-05-15 04:02:34 +000...      0   1.0   \n",
       "22  > tmp <- data.frame(matrix(rnorm(40),10,4, dim...      0   1.0   \n",
       "23  Paradise is here! Our casino paradise is lined...      1   0.0   \n",
       "24  Dear customer.Wanna know how to save much on y...      1   0.0   \n",
       "\n",
       "             source  \n",
       "0       CEAS_08.csv  \n",
       "1       CEAS_08.csv  \n",
       "2       CEAS_08.csv  \n",
       "3       CEAS_08.csv  \n",
       "4       CEAS_08.csv  \n",
       "5         Enron.csv  \n",
       "6         Enron.csv  \n",
       "7         Enron.csv  \n",
       "8         Enron.csv  \n",
       "9         Enron.csv  \n",
       "10         Ling.csv  \n",
       "11         Ling.csv  \n",
       "12         Ling.csv  \n",
       "13         Ling.csv  \n",
       "14         Ling.csv  \n",
       "15  SpamAssasin.csv  \n",
       "16  SpamAssasin.csv  \n",
       "17  SpamAssasin.csv  \n",
       "18  SpamAssasin.csv  \n",
       "19  SpamAssasin.csv  \n",
       "20      TREC_07.csv  \n",
       "21      TREC_07.csv  \n",
       "22      TREC_07.csv  \n",
       "23      TREC_07.csv  \n",
       "24      TREC_07.csv  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label distribution by source (%):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ham (0)</th>\n",
       "      <th>Spam (1)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CEAS_08.csv</th>\n",
       "      <td>44.215150</td>\n",
       "      <td>55.784850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Enron.csv</th>\n",
       "      <td>53.048678</td>\n",
       "      <td>46.951322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ling.csv</th>\n",
       "      <td>83.980413</td>\n",
       "      <td>16.019587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpamAssasin.csv</th>\n",
       "      <td>70.425202</td>\n",
       "      <td>29.574798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TREC_07.csv</th>\n",
       "      <td>45.311308</td>\n",
       "      <td>54.688692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Ham (0)   Spam (1)\n",
       "source                               \n",
       "CEAS_08.csv      44.215150  55.784850\n",
       "Enron.csv        53.048678  46.951322\n",
       "Ling.csv         83.980413  16.019587\n",
       "SpamAssasin.csv  70.425202  29.574798\n",
       "TREC_07.csv      45.311308  54.688692"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic dataset statistics:\n",
      "Total emails: 131346\n",
      "Ham emails: 63953 (48.69%)\n",
      "Spam emails: 67393 (51.31%)\n"
     ]
    }
   ],
   "source": [
    "# Basic dataset analysis showing samples from each source\n",
    "\n",
    "# Get the unique sources\n",
    "sources = merged_df['source'].unique()\n",
    "\n",
    "# Create a dataframe to store samples from each source\n",
    "all_samples = pd.DataFrame()\n",
    "\n",
    "# Get 5 rows from each source\n",
    "for source in sources:\n",
    "    sample = merged_df[merged_df['source'] == source].sample(5, random_state=42)\n",
    "    all_samples = pd.concat([all_samples, sample])\n",
    "\n",
    "# Reset index for better display\n",
    "all_samples = all_samples.reset_index(drop=True)\n",
    "\n",
    "# Display the samples\n",
    "print(f\"Showing 5 random samples from each of the {len(sources)} sources\")\n",
    "display(all_samples)\n",
    "\n",
    "# Display label distribution by source\n",
    "label_dist = merged_df.groupby('source')['label'].value_counts(normalize=True).unstack().fillna(0)\n",
    "label_dist.columns = ['Ham (0)', 'Spam (1)']\n",
    "label_dist = label_dist * 100  # Convert to percentages\n",
    "\n",
    "print(\"\\nLabel distribution by source (%):\")\n",
    "display(label_dist)\n",
    "\n",
    "# Show basic statistics about the dataset\n",
    "print(\"\\nBasic dataset statistics:\")\n",
    "print(f\"Total emails: {len(merged_df)}\")\n",
    "print(f\"Ham emails: {len(merged_df[merged_df['label'] == 0])} ({len(merged_df[merged_df['label'] == 0])/len(merged_df):.2%})\")\n",
    "print(f\"Spam emails: {len(merged_df[merged_df['label'] == 1])} ({len(merged_df[merged_df['label'] == 1])/len(merged_df):.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb0ab98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
